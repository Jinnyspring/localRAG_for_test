import ollama
import chromadb

# ChromaDB ì„¤ì •
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_or_create_collection(name="test_embeddings")


class TestRAG:
    def __init__(self, model='gemma2'):
        self.model = model
        self.context = ""  # ë¬¸ì„œ ë‚´ìš©ì„ ì €ì¥í•  ë³€ìˆ˜

    def embed_and_store(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© í›„ ChromaDBì— ì €ì¥"""
        response = ollama.embeddings(model=self.model, prompt=text)
        embedding = response['embedding']

        # ChromaDBì— ì €ì¥
        collection.add(
            ids=[str(len(collection.get()['ids']) + 1)],  # ê³ ìœ  ID
            embeddings=[embedding],
            metadatas=[{"text": text}]
        )
        self.context = text  # ë¬¸ì„œ ë‚´ìš©ì„ ì €ì¥í•˜ì—¬ ì±—ë´‡ì— í™œìš©

    def embed_file(self, path):
        """íŒŒì¼ì„ ì½ì–´ì„œ ì„ë² ë”© í›„ ì €ì¥"""
        with open(path, 'r', encoding='utf-8') as file:
            text = file.read()
        self.embed_and_store(text)  # ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ê³  ì €ì¥

    def chat(self):
        """ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™”"""
        print("ğŸ“– ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡ ì‹œì‘! 'exit'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")

        while True:
            user_input = input("You: ")
            if user_input.lower() == 'exit':
                print("----CLOSED----.")
                break

            # ë¬¸ì„œ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€í•˜ì—¬ ëŒ€í™” ìš”ì²­
            messages = [
                {"role": "system", "content": "You are a helpful AI assistant. Use the given document as context."},
                {"role": "system", "content": f"Document Context: {self.context}"},
                {"role": "user", "content": user_input}
            ]

            response = ollama.chat(model=self.model, messages=messages)
            print(f"Gemma: {response['message']['content']}")


if __name__ == '__main__':
    test_rag = TestRAG()
    test_rag.embed_file('embed_test.txt')  # ë¬¸ì„œë¥¼ ì„ë² ë”© í›„ ì €ì¥
    test_rag.chat()  # ì±—ë´‡ ì‹œì‘
